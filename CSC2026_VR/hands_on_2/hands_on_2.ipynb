{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76ea9fb-7249-4638-9db8-d4f4817a3548",
   "metadata": {},
   "source": [
    "# Hands-On 2 ‚Äî Rare Events and Variance Reduction with Geant4\n",
    "\n",
    "**47th School of Computing ‚Äì Latin America 2026**  \n",
    "Hands-On Session 2\n",
    "\n",
    "**Lecturer:** Jaime Romero-Barrientos   \n",
    "**Contact:** jaime.romero@cern.ch   \n",
    "Researcher ‚Äî Chilean Nuclear Energy Commission (CCHEN)  \n",
    "Researcher ‚Äî Millennium Institute for Subatomic Physics at the High-Energy Frontier (SAPHIR)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; gap:32px;\">\n",
    "  <img src=\"https://cernbox.cern.ch/remote.php/dav/public-files/3XD5887poIjRXe6/logo_CCHEN.jpg\" width=\"180\"/>\n",
    "  <img src=\"https://cernbox.cern.ch/remote.php/dav/public-files/foYapCY948XIY91/Logo-Saphir.png\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bd5a7-cc8a-4cef-85c7-1ca2914eb5b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Overview\n",
    "\n",
    "This hands-on focuses on Monte Carlo simulation of **rare-event observables** using **Geant4**, with emphasis on:\n",
    "\n",
    "- Event-by-event estimators\n",
    "- Large statistical variance and slow convergence\n",
    "- Diagnosing rare-event problems\n",
    "- Variance reduction through enhanced sampling\n",
    "- Quantitative performance comparison using the Figure of Merit (FOM)\n",
    "\n",
    "You will study a fixed physical problem involving an **ultra-thin target**, where most events contribute zero to the observable.\n",
    "By progressively analyzing analog simulations and then applying variance reduction, you will learn how enhanced sampling can make otherwise impractical simulations feasible‚Äî**while preserving the correct expected value**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39545f-c0ac-433b-af18-5322642f8ca0",
   "metadata": {},
   "source": [
    "---\n",
    "## Computing environment\n",
    "\n",
    "This hands-on is executed using:\n",
    "\n",
    "- **Geant4 version:** 11.3.2  \n",
    "- **Physics list:** FTPF_BERT_HP  \n",
    "- **Computing platform:** SWAN (CERN)  \n",
    "- **Storage:** CERNBox  \n",
    "- **Software stack:** LCG 108 (LHC Computing Grid)\n",
    "\n",
    "All simulations are run inside the SWAN environment to ensure a common and reproducible setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0967dd-003a-4960-9a9d-696f10d9e75b",
   "metadata": {},
   "source": [
    "---\n",
    "## Physical problem: rare photon interactions in a thin target <a name=\"physical-problem-rare-photon-target\"></a>\n",
    "\n",
    "In this hands-on we study **high-energy photon transport through a very thin target**, a prototypical **rare-interaction problem** in Monte Carlo radiation transport.\n",
    "\n",
    "At sufficiently high photon energy and sub-millimeter target thickness, **most primary photons traverse the target without interacting at all**.  \n",
    "Only a **very small fraction** of primaries undergo a physical interaction inside the target volume.\n",
    "\n",
    "As a result:\n",
    "- The quantity of interest is dominated by **rare, discrete events**\n",
    "- Most histories contribute **exactly zero**\n",
    "- Statistical convergence is **slow**\n",
    "\n",
    "This makes the problem **complementary to HO1**:\n",
    "- HO1: many interactions, but very few particles reach the ROI  \n",
    "- HO2: many particles reach the ROI, but very few interactions occur\n",
    "\n",
    "Both are classic **rare-event Monte Carlo problems**.\n",
    "\n",
    "---\n",
    "\n",
    "## Geometry and particle transport <a name=\"geometry-and-particle-transport-ho2\"></a>\n",
    "\n",
    "The simulated geometry consists of:\n",
    "\n",
    "- A **100 MeV photon source** located at `z = -50 cm`, emitting particles along the `+z` axis.\n",
    "- A **very thin target** of thickness **0.1 mm**, defined as the physical volume:\n",
    "  - `test.phys`\n",
    "\n",
    "Because the target is extremely thin at this energy:\n",
    "\n",
    "- Most photons traverse the target without interacting.\n",
    "- Interactions inside the target are **rare**, so the observable is dominated by a small fraction of contributing events.\n",
    "\n",
    "**Important (scoring rule):**  \n",
    "Only interactions for which the **step starts inside `test.phys`** are counted.\n",
    "\n",
    "---\n",
    "\n",
    "## What is scored and why <a name=\"scoring-and-observable\"></a>\n",
    "\n",
    "For each **primary photon**, the simulation records the quantity:\n",
    "\n",
    "$$\n",
    "Q_{\\text{event}}=\\sum_{\\text{collisions in target}} w_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- the sum runs over **all non-transportation interactions** whose step starts inside the target\n",
    "- $w_i$ is the **track weight at the post-step point** of that interaction\n",
    "\n",
    "Interpretation:\n",
    "- $Q_{\\text{event}} = 0$  \n",
    "  ‚Üí the photon did **not** interact in the target\n",
    "- $Q_{\\text{event}} > 0$  \n",
    "  ‚Üí one or more interactions occurred (rare)\n",
    "\n",
    "The run output reports the **mean value per primary**:\n",
    "\n",
    "$$\n",
    "\\langle Q\\rangle=\\frac{1}{N}\\sum_{k=1}^{N} Q_{\\text{event}}^{(k)}\n",
    "$$\n",
    "\n",
    "which you can interpret as the **(weighted) number of target interactions per primary photon**.\n",
    "\n",
    "---\n",
    "\n",
    "## Statistical nature of the problem <a name=\"statistical-nature-ho2\"></a>\n",
    "\n",
    "Because:\n",
    "- most events contribute zero,\n",
    "- and only a tiny fraction contribute a non-zero value,\n",
    "\n",
    "the estimator of $\\langle Q\\rangle$:\n",
    "- converges **slowly**,\n",
    "- has **large relative uncertainty** at moderate $N$,\n",
    "- and is extremely sensitive to rare contributions.\n",
    "\n",
    "This makes it an ideal test case for:\n",
    "- understanding Monte Carlo uncertainty scaling,\n",
    "- and motivating variance reduction techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## Goal of this hands-on <a name=\"goal-ho2\"></a>\n",
    "\n",
    "Your goal is to estimate $\\langle Q\\rangle$ with:\n",
    "\n",
    "- a **relative statistical uncertainty below 1%**,  \n",
    "- **within a fixed wall-clock time budget**.\n",
    "\n",
    "You will:\n",
    "- start from small statistics (many zero events),\n",
    "- observe how the uncertainty scales with $N$,\n",
    "- and use this information to reason about efficiency and feasibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc05c6-754a-44a8-8130-091da3f7a877",
   "metadata": {},
   "source": [
    "## Simulation output\n",
    "\n",
    "Each run produces:\n",
    "\n",
    "### Screen output\n",
    "- A short message indicating where the results were written:\n",
    "  - Per-event file(s):\n",
    "    ```\n",
    "    [GB02] Writing per-event Q to: out/<runTag>_<runID>/eventQ_t<tid>.tsv (thread <tid>)\n",
    "    ```\n",
    "  - Run summary file:\n",
    "    ```\n",
    "    [GB02] Writing run summary to: out/<runTag>_<runID>/summary.tsv\n",
    "    ```\n",
    "  These lines tell you exactly where to find the data for *this* run.\n",
    "\n",
    "- A run-level summary printed at the end:\n",
    "  - `N events`: number of primary histories\n",
    "  - `Mean(Q)`: average **weighted number of collisions in the target** (per primary)\n",
    "  - `StdErr(Mean)`: standard error of the mean\n",
    "  - `Rel. error (%)`: relative uncertainty of the mean (in %)\n",
    "  - `Time (s)`: wall-clock time\n",
    "  - `FOM (1/s)`: figure of merit (higher is better for a fixed target uncertainty)\n",
    "\n",
    "Here the event-level observable is:\n",
    "$$\n",
    "Q_{\\text{event}} = \\sum_{k \\in \\text{collisions in target}} w_k\n",
    "$$\n",
    "\n",
    "and the reported quantity is:\n",
    "$$\n",
    "\\langle Q \\rangle = \\frac{1}{N}\\sum_{i=1}^{N} Q_{\\text{event}}^{(i)} \\, .\n",
    "$$\n",
    "\n",
    "### Files written to disk (`out/<runTag>_<runID>/`)\n",
    "Each run creates a dedicated output folder (unique per execution), containing:\n",
    "\n",
    "- **Per-event data** (one file per thread):\n",
    "  - `eventQ_t0.tsv`, `eventQ_t1.tsv`, ...\n",
    "  - Columns:\n",
    "    - `eventID`: event index\n",
    "    - `eventQ`: the event-level value $Q_{\\text{event}}$\n",
    "\n",
    "- **Run summary**\n",
    "  - `summary.tsv`\n",
    "  - Contains:\n",
    "    - metadata (runTag, runID, number of threads, glob pattern for event files)\n",
    "    - one-row table with: `N`, `MeanQ`, `StdErr`, `RelErr_pct`, `Time_s`, `FOM_1perS`\n",
    "\n",
    "> **Important:** Always use the printed lines `Writing per-event Q to:` and `Writing run summary to:` to locate the correct output folder for your run.  \n",
    "> **After every run:** copy/paste the **full paths** printed by the code, including filenames:\n",
    "> - `.../eventQ_t0.tsv`\n",
    "> - `.../summary.tsv`\n",
    ">  \n",
    "> You will use these exact paths later for the stability and efficiency checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff26a2-4934-46da-8f70-424956e051ee",
   "metadata": {},
   "source": [
    "## Download and compilation\n",
    "\n",
    "We will now download the simulation code from GitHub and compile it inside SWAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94b51b-5a8e-4fbe-ba54-b42366ef598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1#\n",
    "# Executing this cell will download and compile the exercise\n",
    "#\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "%cd \n",
    "%mkdir -p CSC26/VR\n",
    "%cd CSC26/VR\n",
    "print(\"Obtaining source code from Github...\")\n",
    "!git  --no-pager clone https://github.com/jromero-barrientos/hands_on_2.git\n",
    "%mkdir -p hands_on_2/build \n",
    "%cd hands_on_2/build \n",
    "print(\"Running cmake..\")   \n",
    "!cmake .. \n",
    "print(\"Running make\")\n",
    "!make -j \n",
    "\n",
    "# --- Compilation check ---\n",
    "exe = \"exampleGB02\"\n",
    "if os.path.isfile(exe) and os.access(exe, os.X_OK):\n",
    "    print(f\"‚úÖ Compilation successful: '{exe}' found.\")\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå Compilation failed: executable 'exampleGB02' not found.\\n\"\n",
    "        \"Check the output above.\"\n",
    "    )\n",
    "\n",
    "t2 = time()\n",
    "print(\"Installed exercise in {:.2f} minutes\".format((t2-t1)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254dd0a5-0145-4053-9824-8781a4ec25b4",
   "metadata": {},
   "source": [
    "## First analog run (baseline: 10k primaries)\n",
    "\n",
    "We start by running a **baseline analog simulation** with **10,000 primary particles**.\n",
    "\n",
    "- The **physics, geometry, and observable are fixed** throughout the hands-on.\n",
    "- The **random seed is kept fixed** on purpose.\n",
    "- At this stage, we are **not** trying to obtain a precise result.\n",
    "\n",
    "### Why start with this run?\n",
    "\n",
    "This first run serves as a **diagnostic case**:\n",
    "\n",
    "- To observe what happens when the observable is **extremely rare**.\n",
    "- To understand why many events contribute **exactly zero** to the estimator.\n",
    "- To see what a **very large relative uncertainty** looks like in practice.\n",
    "\n",
    "In other words, this is a *‚Äúcase zero‚Äù*:  \n",
    "it tells us **why 10k events are not enough**, rather than giving a useful estimate.\n",
    "\n",
    "### What to record from the output\n",
    "\n",
    "After the run finishes, write down the following quantities from the terminal output:\n",
    "\n",
    "- `N events`\n",
    "- `Mean(Q)`\n",
    "- `StdErr(Mean)`\n",
    "- `Rel. error (%)`\n",
    "- `Time (s)`\n",
    "- `FOM (1/s)`\n",
    "\n",
    "Also, note where the output files are written, using the lines printed by the code:\n",
    "\n",
    "- `[GB02] Writing per-event Q to: ...`\n",
    "- `[GB02] Writing run summary to: ...`\n",
    "\n",
    "You will need these paths later when analyzing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5fd90-4fe5-46b7-a687-c1e7b113eeba",
   "metadata": {},
   "source": [
    "---\n",
    "**Important (do not change the run functions):**  \n",
    "For this hands-on we **must run with 1 thread** so that the simulation writes **a single `.tsv` output file**.  \n",
    "Please **do not modify** the helper/run functions provided in the notebook.  \n",
    "If you change the threading settings, Geant4 will typically produce **multiple `.tsv` files (one per thread)**, which will break the expected workflow and make the analysis confusing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65782e-a3f7-4266-98f6-6b9289c57be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "def run_simulation(macro, *, cwd=\".\", timeout=None, print_output=True):\n",
    "    \"\"\"\n",
    "    Runs the GB02 executable, forcing 1 thread.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    macro : str\n",
    "        Macro filename (e.g., \"run_10k_seedA.mac\") or path to a macro.\n",
    "    cwd : str\n",
    "        Working directory where 'exampleGB02' lives (default: current dir).\n",
    "    timeout : float | None\n",
    "        Optional timeout in seconds.\n",
    "    print_output : bool\n",
    "        If True, prints the program stdout.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        - wall_time_s\n",
    "        - returncode\n",
    "        - stdout\n",
    "        - eventQ_path (if detected)\n",
    "        - summary_path (if detected)\n",
    "    \"\"\"\n",
    "    cwd = Path(cwd).resolve()\n",
    "    exe = cwd / \"exampleGB02\"\n",
    "    macro = str(Path(macro))\n",
    "\n",
    "    if not exe.is_file():\n",
    "        raise FileNotFoundError(f\"Executable not found: {exe}\")\n",
    "\n",
    "    # Force single-thread execution\n",
    "    env = os.environ.copy()\n",
    "    env[\"G4FORCENUMBEROFTHREADS\"] = \"1\"\n",
    "\n",
    "    # Default mode is used (no extra flags)\n",
    "    cmd = [str(exe), \"-m\", macro]\n",
    "\n",
    "    t1 = time()\n",
    "    proc = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(cwd),\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=timeout,\n",
    "        check=False,\n",
    "    )\n",
    "    t2 = time()\n",
    "\n",
    "    stdout = proc.stdout or \"\"\n",
    "    stderr = proc.stderr or \"\"\n",
    "\n",
    "    if print_output:\n",
    "        print(stdout)\n",
    "        if proc.returncode != 0 and stderr.strip():\n",
    "            print(\"\\n--- STDERR ---\\n\")\n",
    "            print(stderr)\n",
    "\n",
    "    # Detect output paths from stdout\n",
    "    eventQ_path = None\n",
    "    summary_path = None\n",
    "    for line in stdout.splitlines():\n",
    "        if \"[GB02] Writing per-event Q to:\" in line:\n",
    "            try:\n",
    "                eventQ_path = line.split(\"to:\", 1)[1].strip().split(\" (thread\", 1)[0].strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "        if \"[GB02] Writing run summary to:\" in line:\n",
    "            try:\n",
    "                summary_path = line.split(\"to:\", 1)[1].strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    result = {\n",
    "        \"wall_time_s\": t2 - t1,\n",
    "        \"returncode\": proc.returncode,\n",
    "        \"stdout\": stdout,\n",
    "        \"eventQ_path\": eventQ_path,\n",
    "        \"summary_path\": summary_path,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n‚úÖ Done. Wall time: {result['wall_time_s']:.3f} s (forced 1 thread)\")\n",
    "    if eventQ_path:\n",
    "        print(f\"üìÑ Per-event file: {eventQ_path}\")\n",
    "    if summary_path:\n",
    "        print(f\"üìÑ Summary file  : {summary_path}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d49720-31d9-4076-9d9f-077ce7a120af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1: Seed A\n",
    "resA = run_simulation(\"run_10k_seedA.mac\", cwd=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070119bb-2233-47c7-9055-fa99d7218654",
   "metadata": {},
   "source": [
    "### Record your results (analog run, 10k primaries)\n",
    "\n",
    "Write down (copy/paste) the following values from the **screen output**:\n",
    "\n",
    "- `N events =`\n",
    "- `Mean(Q) =`\n",
    "- `StdErr(Mean) =`\n",
    "- `Rel. error (%) =`\n",
    "- `Time (s) =`\n",
    "- `FOM (1/s) =`\n",
    "\n",
    "Also copy the output paths printed by the code (you will need them later):\n",
    "\n",
    "- Per-event file: `.../eventQ_t0.tsv`\n",
    "- Summary file: `.../summary.tsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596aea5-83f4-446f-95e2-b49334b81def",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Understanding the simulation output structure\n",
    "\n",
    "\n",
    "Each run writes its results to a directory of the form:\n",
    "\n",
    "`out/<runTag>_<runID>/`\n",
    "\n",
    "Inside that directory you will find:\n",
    "\n",
    "### `summary.tsv`\n",
    "Run-level statistics:\n",
    "- `N`\n",
    "- `MeanQ`\n",
    "- `StdErr`\n",
    "- `RelErr_pct`\n",
    "- `Time_s`\n",
    "- `FOM_1perS`\n",
    "\n",
    "This file answers the question:\n",
    "> *‚ÄúWhat is the estimator value and its uncertainty for this run?‚Äù*\n",
    "\n",
    "### `eventQ_t0.tsv`\n",
    "Per-event data (one line per primary):\n",
    "- `eventID`\n",
    "- `eventQ`\n",
    "\n",
    "This file answers the question:\n",
    "> *‚ÄúHow is the estimator built event by event?‚Äù*\n",
    "\n",
    "You can inspect these files directly, for example:\n",
    "\n",
    "```bash\n",
    "head summary.tsv\n",
    "head eventQ_t0.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921176c-a958-471d-8b5b-c34106f353ae",
   "metadata": {},
   "source": [
    "## Interpreting the first analog run (rare-event behavior)\n",
    "\n",
    "After running the first analog simulation (`N = 10,000`), you should now step back and\n",
    "**interpret what you observed**.\n",
    "\n",
    "Answer the following questions **in your own words**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Event-level behavior: why so many zeros?\n",
    "\n",
    "Look at `eventQ_t0.tsv`.\n",
    "\n",
    "- What fraction of events have `eventQ = 0`?\n",
    "- Why is this expected from:\n",
    "  - the target thickness,\n",
    "  - the photon interaction probability,\n",
    "  - and the definition of `Q_event`?\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Uncertainty: why is the relative error so large?\n",
    "\n",
    "Now look at the summary output.\n",
    "\n",
    "- Why is the **relative error close to 100%**?\n",
    "- Explain the connection between:\n",
    "  - a large fraction of zero-contribution events,\n",
    "  - rare non-zero events,\n",
    "  - and the variance of the estimator.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Reliability of the estimate\n",
    "\n",
    "- Is the reported `Mean(Q)` already a reliable estimate of the true value?\n",
    "- What does ‚Äúreliable‚Äù mean in this context?\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Scaling intuition (before doing anything)\n",
    "\n",
    "Without doing any calculation:\n",
    "\n",
    "- If you increased the number of events from 10k to 20k,\n",
    "  would the situation qualitatively change?\n",
    "- Why or why not?\n",
    "\n",
    "---\n",
    "\n",
    "### 5. First conclusion\n",
    "\n",
    "In one or two sentences:\n",
    "\n",
    "- What is the **core difficulty** of this problem for analog Monte Carlo?\n",
    "- How is this difficulty different from the deep-shielding case in HO1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b6afa-02e1-40ce-9977-4f12b957af44",
   "metadata": {},
   "source": [
    "## Second analog runs: increasing statistics (same physics, same problem)\n",
    "\n",
    "From the previous run you observed that:\n",
    "- Most events have `Q_event = 0`\n",
    "- The estimator is dominated by **rare interactions**\n",
    "- The relative uncertainty is very large at low statistics\n",
    "\n",
    "We now test the most obvious strategy:\n",
    "\n",
    "> **Does simply increasing the number of events solve the problem?**\n",
    "\n",
    "In the next cells you will run the **same simulation**, changing **only** the number of primary events:\n",
    "\n",
    "- 30k events\n",
    "- 50k events\n",
    "- 100k events\n",
    "\n",
    "---\n",
    "\n",
    "### Important rules (for a controlled comparison)\n",
    "\n",
    "- Keep the **same random seed**  \n",
    "  *(this reduces run-to-run noise and makes trends with \\(N\\) easier to interpret in a hands-on setting)*\n",
    "\n",
    "- After each run, you must:\n",
    "  1. Record the key numbers from the **screen output**\n",
    "  2. Record the paths of the output files printed by the program\n",
    "\n",
    "---\n",
    "\n",
    "### Goal of this block\n",
    "\n",
    "By comparing these runs, you should be able to:\n",
    "\n",
    "- Observe how the **relative error** \\(R\\) scales with \\(N\\)\n",
    "- Observe how the **wall time** scales with \\(N\\)\n",
    "- Decide whether increasing statistics alone is a **practical strategy**\n",
    "  for reaching the target uncertainty in this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f3de8-5fc2-4624-8da6-6b21ff7f9791",
   "metadata": {},
   "source": [
    "#### Run the simulation with 30,000 initial particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5e0a6-8b67-4bf3-9181-932a1754387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_30k = run_simulation(\"run_30k_seedA.mac\", cwd=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5baf4dc-721b-4740-be6c-b6191710951e",
   "metadata": {},
   "source": [
    "### Record your results (30k)\n",
    "\n",
    "From the **screen output**, copy:\n",
    "\n",
    "- `N events =`\n",
    "- `Mean(Q) =`\n",
    "- `StdErr(Mean) =`\n",
    "- `Rel. error (%) =`\n",
    "- `Time (s) =`\n",
    "- `FOM (1/s) =`\n",
    "\n",
    "From the printed lines, copy the file locations:\n",
    "\n",
    "- Per-event file: `.../eventQ_t0.tsv`\n",
    "- Summary file: `.../summary.tsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624a23b-d79c-452c-acaf-786d0b0cfcc4",
   "metadata": {},
   "source": [
    "### Quick check (30k): first non-trivial statistics\n",
    "\n",
    "Use the numbers you just copied from the screen output and a quick glance at `eventQ_t0.tsv`.\n",
    "\n",
    "#### A) What do the summary numbers say?\n",
    "\n",
    "1) **Are we anywhere near the target?**\n",
    "- What is `Rel. error (%)`?\n",
    "- Is it already ‚Äúsmall‚Äù, or still clearly large?\n",
    "\n",
    "2) **Mean vs uncertainty**\n",
    "- Is `StdErr(Mean)` of the same order as `Mean(Q)`, or much smaller?\n",
    "- What does that imply about reliability at this N?\n",
    "\n",
    "3) **Cost**\n",
    "- What is `Time (s)`?\n",
    "- Does it already feel ‚Äúcheap‚Äù or ‚Äústarting to cost‚Äù (for a toy problem)?\n",
    "\n",
    "#### B) One-minute look at the event file `eventQ_t0.tsv`\n",
    "\n",
    "4) **Zeros**\n",
    "- Do you see many eventQ = 0 in the first lines?\n",
    "- Based on that, do you expect the estimator to have high variance? (yes/no + one phrase)\n",
    "\n",
    "5) **Type of contributions**\n",
    "- When eventQ is non-zero, does it look like mostly 0/1-like contributions or small continuous values?\n",
    "- One sentence: why does that matter for variance?\n",
    "\n",
    "**‚úÖ One-line checkpoint (mandatory):**\n",
    "At N = 30k, the observable looks rare-event dominated / starting to show signal, because _______________________."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a434a9-d4eb-4f07-92ea-2f0911746062",
   "metadata": {},
   "source": [
    "#### Run the simulation with 50,000 initial particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa9b94-af22-47a2-b94d-570f0a66cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_50k = run_simulation(\"run_50k_seedA.mac\", cwd=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c0407-70b1-459e-8ef3-c8dbaf12ba4d",
   "metadata": {},
   "source": [
    "### Record your results (50k)\n",
    "\n",
    "From the **screen output**, copy:\n",
    "\n",
    "- `N events =`\n",
    "- `Mean(Q) =`\n",
    "- `StdErr(Mean) =`\n",
    "- `Rel. error (%) =`\n",
    "- `Time (s) =`\n",
    "- `FOM (1/s) =`\n",
    "\n",
    "From the printed lines, copy the file locations:\n",
    "\n",
    "- Per-event file: `.../eventQ_t0.tsv`\n",
    "- Summary file: `.../summary.tsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2456-827a-43fa-a75f-2c4b5faf9350",
   "metadata": {},
   "source": [
    "### Quick check (50k): trend spotting\n",
    "\n",
    "Use the numbers you just copied from the **screen output**. Compare only against the **immediately previous run**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) Mean(Q): did it move?\n",
    "\n",
    "Compared to the previous run, `Mean(Q)` is:\n",
    "- ‚òê up\n",
    "- ‚òê down\n",
    "- ‚òê ~same\n",
    "\n",
    "Write the two values (previous ‚Üí current):\n",
    "- Mean(Q): __________ ‚Üí __________\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) Relative error: did it drop meaningfully?\n",
    "\n",
    "`Rel. error (%)` is:\n",
    "- ‚òê lower\n",
    "- ‚òê ~same (barely changed)\n",
    "\n",
    "Write the two values (previous ‚Üí current):\n",
    "- Rel. error (%): __________ ‚Üí __________\n",
    "\n",
    "Approximate improvement factor (previous / current):\n",
    "- $R_{\\text{prev}}/R_{\\text{curr}} \\approx$ ________\n",
    "\n",
    "Circle the closest:\n",
    "- ‚òê ~1.2√ó\n",
    "- ‚òê ~1.5√ó\n",
    "- ‚òê ~2√ó\n",
    "- ‚òê >2√ó\n",
    "\n",
    "One sentence: does this feel like ‚Äúfast convergence‚Äù or ‚Äúslow convergence‚Äù? Why?\n",
    "- _____________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Time: does it scale with N?\n",
    "\n",
    "Write the two values (previous ‚Üí current):\n",
    "- Time (s): __________ ‚Üí __________\n",
    "\n",
    "Compute the ratios:\n",
    "- $N_{\\text{curr}}/N_{\\text{prev}} =$ ________\n",
    "- $T_{\\text{curr}}/T_{\\text{prev}} =$ ________\n",
    "\n",
    "Interpretation (pick one):\n",
    "- ‚òê roughly proportional (expected for a stable per-event cost)\n",
    "- ‚òê more than proportional (overhead / variability / noise)\n",
    "- ‚òê less than proportional (measurement noise / caching effects)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) FOM: did efficiency improve?\n",
    "\n",
    "Write the two values (previous ‚Üí current):\n",
    "- FOM (1/s): __________ ‚Üí __________\n",
    "\n",
    "Compute:\n",
    "- $\\mathrm{FOM}_{\\text{curr}}/\\mathrm{FOM}_{\\text{prev}} =$ ________\n",
    "\n",
    "Interpretation (pick one):\n",
    "- ‚òê FOM improved\n",
    "- ‚òê FOM stayed similar\n",
    "- ‚òê FOM got worse\n",
    "\n",
    "One sentence: why can FOM fail to improve in analog rare-event runs?\n",
    "- _____________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "### One-line checkpoint (mandatory)\n",
    "\n",
    "From $N=$ ________ ‚Üí ________, $R$ went **________**, $T$ went **________**, and FOM went **________**.  \n",
    "This still feels **rare-event dominated / stabilizing** because ________________________________."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6187e36-b42d-492f-a21a-542c64a8dba0",
   "metadata": {},
   "source": [
    "#### Run the simulation with 100,000 initial particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d67b5-dd99-40fc-8e42-a15ddde8602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_100k = run_simulation(\"run_100k_seedA.mac\", cwd=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653dc09-449d-4f97-bebe-ede9502298b4",
   "metadata": {},
   "source": [
    "### Record your results (100k)\n",
    "\n",
    "From the **screen output**, copy:\n",
    "\n",
    "- `N events =`\n",
    "- `Mean(Q) =`\n",
    "- `StdErr(Mean) =`\n",
    "- `Rel. error (%) =`\n",
    "- `Time (s) =`\n",
    "- `FOM (1/s) =`\n",
    "\n",
    "From the printed lines, copy the file locations:\n",
    "\n",
    "- Per-event file: `.../eventQ_t0.tsv`\n",
    "- Summary file: `.../summary.tsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdec64-9d79-484f-83af-04427ac85186",
   "metadata": {},
   "source": [
    "## Closing the analog phase: observation ‚Üí prediction\n",
    "\n",
    "You have now run the **same analog simulation** with increasing statistics:\n",
    "\n",
    "- 10k events  \n",
    "- 30k events  \n",
    "- 50k events  \n",
    "- 100k events  \n",
    "\n",
    "Only the number of primary events changed.\n",
    "\n",
    "This block serves two purposes:\n",
    "1. Consolidate what you have **observed empirically**\n",
    "2. Use that observation to **predict** how far brute-force Monte Carlo can realistically go\n",
    "\n",
    "---\n",
    "\n",
    "### 1. What you observed (empirical behavior)\n",
    "\n",
    "Based on your runs up to **100k events**:\n",
    "\n",
    "- How does the relative error $R$ change as $N$ increases?\n",
    "- Is the improvement:\n",
    "  - rapid?\n",
    "  - or slow?\n",
    "\n",
    "Answer qualitatively:\n",
    "- Is $R$ anywhere near the **1% target**?\n",
    "- Roughly what fraction of events still have $Q_{\\text{event}} = 0$?\n",
    "\n",
    "Explain briefly:\n",
    "- Why do most primaries still contribute nothing?\n",
    "- Why does this lead to large variance?\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Predicting the cost of 1% precision\n",
    "\n",
    "For an unbiased Monte Carlo estimator with finite variance, the relative error scales as:\n",
    "\n",
    "$$\n",
    "R \\propto \\frac{1}{\\sqrt{N}}\n",
    "$$\n",
    "\n",
    "This implies:\n",
    "\n",
    "$$\n",
    "N_{\\text{target}} = N_0\n",
    "\\left( \\frac{R_0}{R_{\\text{target}}} \\right)^2\n",
    "$$\n",
    "\n",
    "Using your **100k events** run as reference:\n",
    "\n",
    "1. Estimate the order of magnitude of $N_{1\\%}$ needed to reach $R = 1\\%$.\n",
    "2. Assuming wall time scales linearly with $N$, estimate the required execution time.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Reality check\n",
    "\n",
    "Based on your estimates:\n",
    "\n",
    "- Would running up to $N_{1\\%}$ be feasible during this hands-on?\n",
    "\n",
    "\n",
    "Write a short conclusion (2‚Äì3 lines).\n",
    "\n",
    "---\n",
    "\n",
    "### Preliminary conclusion (analog Monte Carlo)\n",
    "\n",
    "At this point you should conclude that:\n",
    "\n",
    "- The estimator is **correct and unbiased**\n",
    "- But the **cost of brute-force statistics grows prohibitively fast**\n",
    "- Reaching 1% precision by increasing $N$ alone is not a viable strategy\n",
    "  for this rare-event observable\n",
    "\n",
    "This naturally raises the next question:\n",
    "\n",
    "> *Can we reduce the variance without changing the physics?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6ed19-6936-4159-88ac-0934131280ef",
   "metadata": {},
   "source": [
    "## Stepping back before changing strategy\n",
    "\n",
    "Before moving on to variance reduction, pause for a short group discussion.\n",
    "\n",
    "Up to this point, you have:\n",
    "- Run multiple analog simulations\n",
    "- Observed slow convergence\n",
    "- Estimated the prohibitive cost of brute-force statistics\n",
    "\n",
    "Now we step back and reflect more generally on *why* this problem behaves this way,\n",
    "and what that implies for Monte Carlo simulations beyond this specific example.\n",
    "\n",
    "### 1. What makes an observable ‚Äúdifficult‚Äù in Monte Carlo?\n",
    "- Is the difficulty due to the physical rarity of contributing interactions, or due to the sampling strategy we choose (analog vs biased)?\n",
    "- In this problem, what fraction of events actually contribute to the estimator?\n",
    "- How does a large population of zero-contribution events affect variance?\n",
    "\n",
    "### 2. Why doesn‚Äôt brute-force statistics scale well here?\n",
    "- Even if the estimator is unbiased, why can brute-force $N$ still be impractical?\n",
    "- What is the relationship between rarity, variance, and computational cost?\n",
    "\n",
    "### 3. How could one reduce variance *without changing the physics*?\n",
    "- Think in general terms (no implementation details yet).\n",
    "- What could you do to:\n",
    "  - sample the ‚Äúimportant‚Äù events more often?\n",
    "  - avoid wasting computation on events that contribute nothing?\n",
    "\n",
    "### 4. How should efficiency be measured?\n",
    "- Is wall-clock time alone enough?\n",
    "- Is statistical uncertainty alone enough?\n",
    "- Which metric combines **precision and cost** into a single number?\n",
    "\n",
    "> Keep these questions in mind ‚Äî they will directly motivate the next part of the hands-on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efed503-21ef-4088-b55d-258104d73cfd",
   "metadata": {},
   "source": [
    "## Variance reduction: what is actually happening?\n",
    "\n",
    "Up to now, we have been running the simulation using **default (analog) Monte Carlo sampling**.\n",
    "\n",
    "You have seen that, for this problem:\n",
    "- most events contribute **zero**,\n",
    "- the relative uncertainty decreases very slowly,\n",
    "- reaching the target precision by brute force is impractical.\n",
    "\n",
    "In this block, we will run **the same physical problem**, with **the same geometry and observable**, but using a **variance reduction (VR) technique** designed to address exactly this situation.\n",
    "\n",
    "This is *not* a new concept: the underlying ideas were introduced in the **theory lectures**.  \n",
    "Here, you will see their **practical impact** on a rare-event observable.\n",
    "\n",
    "Before running anything, it is important to be explicit about:\n",
    "- **Which variance reduction method is used in this exercise**\n",
    "- **What changes in the simulation**\n",
    "- **What does *not* change**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc1a1c-3d06-4d6a-b969-8d6c066ceae0",
   "metadata": {},
   "source": [
    "### What changes ‚Äî and what does not\n",
    "\n",
    "Variance reduction is allowed to change **how we sample**, but it must not change **what we are estimating**.\n",
    "\n",
    "**What changes (by design):**\n",
    "- The **sampling strategy** inside the target (we make rare interactions appear more often)\n",
    "- The **distribution of event contributions** (many more events become non-zero)\n",
    "- The **statistical weights** carried by tracks/steps\n",
    "- The **variance and convergence behavior** of the estimator\n",
    "\n",
    "**What does not change (physics and definition):**\n",
    "- Geometry\n",
    "- Physics models and cross sections\n",
    "- The definition of the observable\n",
    "- The **true expectation value** we are trying to estimate\n",
    "\n",
    "The non-negotiable requirement is **unbiasedness**:\n",
    "$$\n",
    "\\langle Q_{\\text{VR}} \\rangle = \\langle Q_{\\text{analog}} \\rangle\n",
    "$$\n",
    "\n",
    "The intended benefit is **variance reduction**, i.e. reaching the same precision with less CPU time.\n",
    "In a *successful* VR configuration, we expect:\n",
    "$$\n",
    "\\mathrm{Var}(Q_{\\text{VR}}) < \\mathrm{Var}(Q_{\\text{analog}})\n",
    "$$\n",
    "\n",
    "However, this is **not automatic**: a poor VR setup can produce large weight fluctuations\n",
    "and even increase the variance.  \n",
    "That is why we will later perform the three checks: **accuracy, stability, and efficiency**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee9bcf-03ca-4d50-a5e4-d0f6f116fdea",
   "metadata": {},
   "source": [
    "---\n",
    "## Run with biased sampling (same physics, different sampling)\n",
    "\n",
    "We now repeat the **same physical simulation** and compute the **same observable**,\n",
    "but using **biased sampling (variance reduction)** instead of analog Monte Carlo.\n",
    "\n",
    "This is the first point where we can directly test whether variance reduction:\n",
    "- preserves **accuracy**, and\n",
    "- improves **efficiency** for this rare-event observable.\n",
    "\n",
    "---\n",
    "\n",
    "### What you must do\n",
    "1. Run **10k events** with variance reduction enabled.\n",
    "2. Record the **same metrics** as in the analog runs:\n",
    "   - `N events`\n",
    "   - `Mean(Q)`\n",
    "   - `StdErr(Mean)`\n",
    "   - `Rel. error (%)`\n",
    "   - `Time (s)`\n",
    "   - `FOM (1/s)`\n",
    "\n",
    "3. Compare the results against your **best analog reference run**\n",
    "   (typically the **100k events analog run**).\n",
    "\n",
    "---\n",
    "\n",
    "### What to focus on\n",
    "\n",
    "When comparing **VR (10k)** to **analog (100k)**, check:\n",
    "\n",
    "- **Accuracy**\n",
    "  - Is `Mean(Q)` consistent with the analog result **within uncertainties**?\n",
    "\n",
    "- **Precision**\n",
    "  - How much do `StdErr(Mean)` and `Rel. error (%)` change?\n",
    "\n",
    "- **Efficiency**\n",
    "  - How does the **FOM (1/s)** compare between the two runs?\n",
    "\n",
    "- **Cost per event**\n",
    "  - Does the runtime per event increase?\n",
    "  - Why might this happen even if the uncertainty decreases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742d7a6-95e0-4c46-9810-3ab1ef12afb7",
   "metadata": {},
   "source": [
    "---\n",
    "**Important (do not change the run functions):**  \n",
    "For this hands-on we **must run with 1 thread** so that the simulation writes **a single `.tsv` output file**.  \n",
    "Please **do not modify** the helper/run functions provided in the notebook.  \n",
    "If you change the threading settings, Geant4 will typically produce **multiple `.tsv` files (one per thread)**, which will break the expected workflow and make the analysis confusing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b43e45-0b95-41b0-b120-67799bf43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "def run_simulation_biased(macro, *, cwd=\".\", timeout=None, print_output=True):\n",
    "    \"\"\"\n",
    "    Runs the GB02 executable in enhanced sampling mode, forcing 1 thread.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    macro : str\n",
    "        Macro filename (e.g., \"run_10k_seedA.mac\") or path to a macro.\n",
    "    cwd : str\n",
    "        Working directory where 'exampleGB02' lives (default: current dir).\n",
    "    timeout : float | None\n",
    "        Optional timeout in seconds.\n",
    "    print_output : bool\n",
    "        If True, prints program stdout.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        - wall_time_s\n",
    "        - returncode\n",
    "        - stdout\n",
    "        - eventQ_path (if detected)\n",
    "        - summary_path (if detected)\n",
    "    \"\"\"\n",
    "    cwd = Path(cwd).resolve()\n",
    "    exe = cwd / \"exampleGB02\"\n",
    "    macro = str(Path(macro))\n",
    "\n",
    "    if not exe.is_file():\n",
    "        raise FileNotFoundError(f\"Executable not found: {exe}\")\n",
    "\n",
    "    # Force single-thread execution\n",
    "    env = os.environ.copy()\n",
    "    env[\"G4FORCENUMBEROFTHREADS\"] = \"1\"\n",
    "\n",
    "    # Enhanced sampling mode (kept internal on purpose)\n",
    "    cmd = [str(exe), \"-m\", macro, \"-b\", \"on\"]\n",
    "\n",
    "    t1 = time()\n",
    "    proc = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(cwd),\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=timeout,\n",
    "        check=False,\n",
    "    )\n",
    "    t2 = time()\n",
    "\n",
    "    stdout = proc.stdout or \"\"\n",
    "    stderr = proc.stderr or \"\"\n",
    "\n",
    "    if print_output:\n",
    "        print(stdout)\n",
    "        if proc.returncode != 0 and stderr.strip():\n",
    "            print(\"\\n--- STDERR ---\\n\")\n",
    "            print(stderr)\n",
    "\n",
    "    # Detect output paths from stdout\n",
    "    eventQ_path = None\n",
    "    summary_path = None\n",
    "    for line in stdout.splitlines():\n",
    "        if \"[GB02] Writing per-event Q to:\" in line:\n",
    "            try:\n",
    "                eventQ_path = line.split(\"to:\", 1)[1].strip().split(\" (thread\", 1)[0].strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "        if \"[GB02] Writing run summary to:\" in line:\n",
    "            try:\n",
    "                summary_path = line.split(\"to:\", 1)[1].strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    result = {\n",
    "        \"wall_time_s\": t2 - t1,\n",
    "        \"returncode\": proc.returncode,\n",
    "        \"stdout\": stdout,\n",
    "        \"eventQ_path\": eventQ_path,\n",
    "        \"summary_path\": summary_path,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n‚úÖ Done. Wall time: {result['wall_time_s']:.3f} s (forced 1 thread)\")\n",
    "    if eventQ_path:\n",
    "        print(f\"üìÑ Per-event file: {eventQ_path}\")\n",
    "    if summary_path:\n",
    "        print(f\"üìÑ Summary file  : {summary_path}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc84cd-cbb1-4b48-84bb-fd6adc032d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_10k_biased = run_simulation_biased(\"run_10k_seedA.mac\", cwd=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f61bb-5e02-406e-a5ff-f8c6a0ea0621",
   "metadata": {},
   "source": [
    "### Record your results (variance reduction ON)\n",
    "\n",
    "From the **screen output**, write down:\n",
    "\n",
    "- `N events =`\n",
    "- `Mean(Q) =`\n",
    "- `StdErr(Mean) =`\n",
    "- `Rel. error (%) =`\n",
    "- `Time (s) =`\n",
    "- `FOM (1/s) =`\n",
    "\n",
    "Also record the output files:\n",
    "- Per-event file: `.../eventQ_t0.tsv`\n",
    "- Summary file: `.../summary.tsv`\n",
    "\n",
    "You will use these results in the final comparison and discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6f99b-fc57-46d8-9297-6a5f1bfff392",
   "metadata": {},
   "source": [
    "### Discussion: first comparison (biased vs analog)\n",
    "\n",
    "You now have everything you need to perform the **first comparison** between **analog Monte Carlo** and **variance reduction**, for the *same physical problem*.\n",
    "\n",
    "Answer briefly:\n",
    "\n",
    "1. **Accuracy**  \n",
    "   Is the mean value obtained with variance reduction consistent with the analog result\n",
    "   (within statistical uncertainties)?\n",
    "\n",
    "2. **Precision**  \n",
    "   How much did the relative error decrease compared to the analog case?\n",
    "\n",
    "3. **Efficiency**  \n",
    "   How does the Figure of Merit (FOM) change?\n",
    "\n",
    "4. **Computational cost**  \n",
    "   Did the runtime per event increase or decrease? Why?\n",
    "\n",
    "5. **Practical relevance**  \n",
    "   Based on these results, when would variance reduction be **essential**\n",
    "   rather than merely optional?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb286b-86eb-4107-94df-426994388b1f",
   "metadata": {},
   "source": [
    "## Importing a precomputed high-statistics analog reference (100 million events)\n",
    "\n",
    "Just like in **Hands-On 1**, we will use a **precomputed analog run** with:\n",
    "\n",
    "$$\n",
    "N = 100{,}000{,}000\n",
    "$$\n",
    "\n",
    "This gives us a **high-statistics reference** for the **accuracy check** (unbiasedness), without wasting the hands-on time running an extremely long job.\n",
    "\n",
    "---\n",
    "\n",
    "### Where is the file?\n",
    "\n",
    "If you want to inspect it directly, the summary file is located at:\n",
    "\n",
    "`~/CSC26/VR/hands_on_1/pcruns/summary_100M.tsv`\n",
    "\n",
    "For convenience, here is the content we will use:\n",
    "\n",
    "| N | MeanQ | StdErr | RelErr_pct | Time_s | FOM_1perS |\n",
    "|---:|---:|---:|---:|---:|---:|\n",
    "| 100000000 | 1.3044e-04 | 1.1423e-06 | 0.8757 | 6.1318e+03 | 2.1266e+00 |\n",
    "\n",
    "**Note the execution time:** this 100M analog run took **6,131.8 s**, i.e. **a bit over 100 minutes**.\n",
    "\n",
    "---\n",
    "\n",
    "### What we will do with it\n",
    "\n",
    "In **Check 1 (Accuracy)**, you will compare your **VR (10k)** result against this **high-statistics analog reference** using the mean values and their uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c4bbf-9713-489f-a50c-df139849838d",
   "metadata": {},
   "source": [
    "## Check 1 ‚Äî Accuracy: does variance reduction preserve the mean?\n",
    "\n",
    "Up to now, you have:\n",
    "\n",
    "- Identified the observable ‚ü®Q‚ü© as a **rare-event quantity**,\n",
    "- Observed very slow convergence with **analog Monte Carlo**,\n",
    "- Enabled **variance reduction** to enhance the sampling of rare interactions.\n",
    "\n",
    "We now move from *qualitative observation* to a **quantitative validation**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this check matters\n",
    "\n",
    "Variance reduction techniques are allowed to:\n",
    "- modify the **sampling process**,\n",
    "- increase the frequency of rare events,\n",
    "- introduce **statistical weights**,\n",
    "\n",
    "but they must satisfy one strict requirement:\n",
    "\n",
    "> **They must not change the physical expectation value of the observable.**\n",
    "\n",
    "In other words, variance reduction must be **unbiased**.\n",
    "\n",
    "Formally, this means:\n",
    "$$\n",
    "\\langle Q_{\\text{VR}} \\rangle = \\langle Q_{\\text{analog}} \\rangle\n",
    "$$\n",
    "\n",
    "Because we work with *finite statistics*, the two values will never be exactly equal.\n",
    "What matters is whether their difference is **consistent with statistical fluctuations**.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparing two estimates with uncertainties\n",
    "\n",
    "Let:\n",
    "- $\\mu_{\\text{analog}}$ = mean ‚ü®Q‚ü© from the **analog reference run**\n",
    "- $\\mu_{\\text{VR}}$     = mean ‚ü®Q‚ü© from the **variance-reduced run**\n",
    "- $\\sigma_{\\text{analog}}$ and $\\sigma_{\\text{VR}}$ = their **standard errors**\n",
    "  (reported as `StdErr(Mean)`)\n",
    "\n",
    "We define the difference:\n",
    "$$\n",
    "\\Delta = \\mu_{\\text{VR}} - \\mu_{\\text{analog}}\n",
    "$$\n",
    "\n",
    "Assuming the two runs are statistically independent, the uncertainty on this difference is:\n",
    "$$\n",
    "\\sigma_\\Delta = \\sqrt{\\sigma_{\\text{VR}}^2 + \\sigma_{\\text{analog}}^2}\n",
    "$$\n",
    "\n",
    "We then form a normalized deviation (a *z-score*):\n",
    "$$\n",
    "z = \\frac{\\mu_{\\text{VR}} - \\mu_{\\text{analog}}}\n",
    "         {\\sqrt{\\sigma_{\\text{VR}}^2 + \\sigma_{\\text{analog}}^2}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### How to interpret the result\n",
    "\n",
    "As a practical rule of thumb:\n",
    "\n",
    "- $|z| \\lesssim 2$  \n",
    "  ‚Üí The VR and analog results are **statistically compatible**  \n",
    "  ‚Üí No evidence of bias\n",
    "\n",
    "- $|z| \\gg 2$  \n",
    "  ‚Üí Suspicious  \n",
    "  ‚Üí Could indicate bias, underestimated uncertainties, or implementation issues\n",
    "\n",
    "This is **not** a formal hypothesis test, but a robust diagnostic\n",
    "used routinely in Monte Carlo validation.\n",
    "\n",
    "---\n",
    "\n",
    "### What to do\n",
    "\n",
    "1. Use:\n",
    "   - the **high-statistics analog reference** (e.g. 100M events),\n",
    "   - the **variance-reduced run** (e.g. 10k events).\n",
    "2. Write down:\n",
    "   - $\\mu_{\\text{analog}}$, $\\sigma_{\\text{analog}}$\n",
    "   - $\\mu_{\\text{VR}}$, $\\sigma_{\\text{VR}}$\n",
    "3. Compute $z$ and interpret it using the criteria above.\n",
    "\n",
    "üëâ At this stage, focus on **correctness**, not on speed or efficiency.\n",
    "A variance reduction method that is fast but biased is unusable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d259-c553-4c30-8357-9c7651794efc",
   "metadata": {},
   "source": [
    "## Evaluating variance reduction: three essential checks\n",
    "\n",
    "So far, you have:\n",
    "\n",
    "- Understood the physical problem and the observable,\n",
    "- Run **analog Monte Carlo** simulations and observed very slow convergence,\n",
    "- Identified this as a **rare-event observable** dominated by zero-contribution events,\n",
    "- Enabled **variance reduction** via forced collision biasing.\n",
    "\n",
    "At this point, we move from *exploration* to **evaluation**.\n",
    "\n",
    "Whenever a variance reduction (VR) technique is introduced, it must be assessed carefully.\n",
    "Reducing statistical uncertainty alone is **not sufficient**.\n",
    "\n",
    "In this hands-on, we will evaluate variance reduction using **three essential checks**,\n",
    "which reflect best practice in real Monte Carlo simulations.\n",
    "\n",
    "---\n",
    "\n",
    "### The three checks\n",
    "\n",
    "**1. Accuracy (unbiasedness)**  \n",
    "Does variance reduction preserve the *physical expectation value* of the observable?\n",
    "\n",
    "> The mean value ‚ü®Q‚ü© obtained with VR must remain consistent with the analog result,\n",
    "> within statistical uncertainties.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Efficiency (cost vs precision)**  \n",
    "Does variance reduction reduce uncertainty *fast enough* to justify its additional cost?\n",
    "\n",
    "> This is quantified using the **Figure of Merit (FOM)**, which combines precision and runtime.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Stability (weight behaviour and pathologies)**  \n",
    "Does variance reduction introduce rare but extreme weighted events\n",
    "that dominate the estimator?\n",
    "\n",
    "> We want to avoid estimators controlled by a handful of pathological events\n",
    "> with very large statistical weights.\n",
    "\n",
    "---\n",
    "\n",
    "In the next cells, you will perform these three checks **step by step**, using the results\n",
    "you have already produced.\n",
    "\n",
    "We start with the most fundamental one:\n",
    "\n",
    "‚û°Ô∏è **Check 1 ‚Äî Accuracy: does variance reduction preserve the mean?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae671f-3dc5-4d68-b789-6160519da82a",
   "metadata": {},
   "source": [
    "## Check 2 ‚Äî Efficiency: does variance reduction actually pay off?\n",
    "\n",
    "So far, you have checked **accuracy** (unbiasedness):  \n",
    "variance reduction must preserve the mean ‚ü®Q‚ü©.\n",
    "\n",
    "Now we ask the practical question:\n",
    "\n",
    "> **How much CPU time is required to reach a given statistical precision?**\n",
    "\n",
    "In Monte Carlo, ‚Äúfaster‚Äù is meaningless unless we include **precision**.\n",
    "That is why we compare methods using the **Figure of Merit (FOM)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Definition: Figure of Merit (FOM)\n",
    "\n",
    "For a given estimator, we define:\n",
    "\n",
    "- Relative error:\n",
    "$$\n",
    "R = \\frac{\\sigma}{\\mu}\n",
    "$$\n",
    "\n",
    "- Figure of Merit:\n",
    "$$\n",
    "\\mathrm{FOM} = \\frac{1}{R^2\\,T}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mu$ is the estimated mean (here: ‚ü®Q‚ü©),\n",
    "- $\\sigma$ is the standard error (`StdErr(Mean)`),\n",
    "- $T$ is the wall time (seconds).\n",
    "\n",
    "**Interpretation:** a larger FOM means *more precision per unit CPU time*.\n",
    "\n",
    "---\n",
    "\n",
    "### What to compare (use your recorded screen outputs)\n",
    "\n",
    "Use:\n",
    "\n",
    "- **Analog run:** your best analog run (typically **100k events**)\n",
    "- **VR run:** the variance-reduced run (**10k events**)\n",
    "\n",
    "For each run, write down:\n",
    "- $R$ (or `Rel. error (%)`)\n",
    "- $T$ (seconds)\n",
    "- FOM (if printed)\n",
    "\n",
    "If FOM is not printed (or to double-check it), compute it from:\n",
    "$$\n",
    "\\mathrm{FOM} = \\frac{1}{R^2\\,T}\n",
    "$$\n",
    "(use $R$ as a **fraction**, not percent).\n",
    "\n",
    "---\n",
    "\n",
    "### Efficiency metric: ‚Äúhow many times better?‚Äù\n",
    "\n",
    "Compute the efficiency gain:\n",
    "$$\n",
    "G = \\frac{\\mathrm{FOM}_{\\mathrm{VR}}}{\\mathrm{FOM}_{\\mathrm{analog}}}\n",
    "$$\n",
    "\n",
    "- If $G \\gg 1$, VR is more efficient.\n",
    "- If $G \\approx 1$, VR buys little (or overhead cancels the variance gain).\n",
    "- If $G < 1$, VR is not worth it (bad configuration, wrong method, or too much overhead).\n",
    "\n",
    "---\n",
    "\n",
    "### Cost-equivalence sanity check\n",
    "\n",
    "Assume the analog run follows the ideal scaling:\n",
    "$$\n",
    "R \\propto \\frac{1}{\\sqrt{N}}\n",
    "$$\n",
    "\n",
    "Let $(N_0, R_0, T_0)$ be your **analog** reference (e.g. 100k),\n",
    "and let $R_{\\mathrm{VR}}$ be the relative error from your VR run.\n",
    "\n",
    "Estimate how many **analog** events would be required to match VR precision:\n",
    "$$\n",
    "N_{\\mathrm{eq}} = N_0\\left(\\frac{R_0}{R_{\\mathrm{VR}}}\\right)^2\n",
    "$$\n",
    "\n",
    "Assuming wall time scales linearly with $N$, estimate:\n",
    "$$\n",
    "T_{\\mathrm{eq}} \\approx T_0\\left(\\frac{N_{\\mathrm{eq}}}{N_0}\\right)\n",
    "$$\n",
    "\n",
    "This answers the question:\n",
    "\n",
    "> **How long would brute-force analog need to run to reach the same precision as VR?**\n",
    "\n",
    "---\n",
    "\n",
    "### What to conclude (keep it quantitative)\n",
    "\n",
    "1) Report $G=\\mathrm{FOM}_{\\mathrm{VR}}/\\mathrm{FOM}_{\\mathrm{analog}}$.  \n",
    "2) State whether the efficiency gain comes mainly from:\n",
    "- a strong reduction in $R$,\n",
    "- or a reduction in $T$ (rare),\n",
    "- or both.\n",
    "3) If you did the equivalence check, report $(N_{\\mathrm{eq}}, T_{\\mathrm{eq}})$ as an order of magnitude.\n",
    "\n",
    "üëâ Efficiency is the objective of variance reduction ‚Äî but it only matters **after** you trust accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1343a946-ca88-40fe-b866-f1458d68e65e",
   "metadata": {},
   "source": [
    "## Check 3 ‚Äî Stability: does VR create pathological event weights?\n",
    "\n",
    "You have already checked:\n",
    "\n",
    "- **Accuracy:** VR must preserve the physical mean $\\langle Q\\rangle$.\n",
    "- **Efficiency:** VR should reduce uncertainty fast enough to justify its cost.\n",
    "\n",
    "Now we perform a **stability check**, which often reveals subtle problems in\n",
    "variance-reduction implementations.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this check matters\n",
    "\n",
    "Even if a VR method is **unbiased**, it can still be **practically unusable** if the estimator\n",
    "is dominated by:\n",
    "\n",
    "- rare events with **huge statistical weights**, or\n",
    "- event-by-event contributions with **heavy tails** (‚Äúspikes‚Äù).\n",
    "\n",
    "In that situation:\n",
    "- the mean may look reasonable,\n",
    "- but convergence becomes erratic,\n",
    "- and the reported uncertainty can be misleading.\n",
    "\n",
    "---\n",
    "\n",
    "### What we inspect (event-level contributions)\n",
    "\n",
    "We inspect the per-event contributions stored in:\n",
    "\n",
    "- `eventQ_t0.tsv`  \n",
    "  (one line per event: `eventID`, `eventQ`)\n",
    "\n",
    "This file shows how the estimator behaves **event by event**, not just in a run summary.\n",
    "\n",
    "We will compare:\n",
    "\n",
    "- **Analog baseline:** 100k events  \n",
    "- **VR run:** 10k events  \n",
    "\n",
    "(Different $N$ is fine here ‚Äî we are inspecting **shape/pathologies**, not comparing precision.)\n",
    "\n",
    "---\n",
    "\n",
    "### Diagnostics we compute\n",
    "\n",
    "For each run:\n",
    "\n",
    "1) **Zero fraction**\n",
    "- fraction of events with `eventQ = 0`\n",
    "\n",
    "2) **Dominance by extreme events**\n",
    "- fraction of the total sum carried by:\n",
    "  - the largest event (**top-1**)\n",
    "  - the 10 largest events (**top-10**)\n",
    "\n",
    "3) **Spike indicator**\n",
    "- $\\max(Q_{\\text{event}})/\\mathrm{median}(Q_{\\text{event}})$  \n",
    "  (very large values are a warning sign)\n",
    "\n",
    "---\n",
    "\n",
    "### Plots we use (and what they mean)\n",
    "\n",
    "- **Histogram of `eventQ`** (log scale on the y-axis)  \n",
    "  Helps reveal whether there are rare but very large contributions.\n",
    "\n",
    "- **Rank (tail) plot**  \n",
    "  Sort events by contribution, from largest to smallest, and plot\n",
    "  $Q_{\\text{event}}(\\text{rank})$ on log‚Äìlog axes:\n",
    "\n",
    "  - rank = 1 is the largest contributing event,\n",
    "  - rank = 2 is the second largest, etc.\n",
    "\n",
    "  This plot answers a simple question:\n",
    "  **Is the total score shared across many events, or dominated by a tiny number of extreme events?**\n",
    "\n",
    "---\n",
    "\n",
    "### How to interpret the comparison (analog vs VR)\n",
    "\n",
    "In this problem, **analog sampling is expected to look sparse**:\n",
    "many events have `eventQ = 0`, and the signal can be carried by relatively few events.\n",
    "\n",
    "A **healthy VR setup** should typically move the estimator in the right direction:\n",
    "\n",
    "- **more** non-zero contributing events (lower `eventQ = 0` fraction),\n",
    "- **less** dominance by top-1/top-10 events,\n",
    "- no isolated extreme spikes that make the result hinge on a handful of events.\n",
    "\n",
    "A **pathological VR setup** is a red flag if VR introduces or worsens:\n",
    "\n",
    "- extreme domination by a tiny number of events,\n",
    "- very large max/median ratios,\n",
    "- an unusually long/heavy tail in the rank plot.\n",
    "\n",
    "Such behavior can make uncertainty estimates unreliable even if the mean looks correct.\n",
    "\n",
    "---\n",
    "\n",
    "### What happens next (helpers and workflow)\n",
    "\n",
    "In the next code cells, we provide helper functions that:\n",
    "\n",
    "- load `eventQ_t0.tsv` files into Python,\n",
    "- compute the diagnostics above,\n",
    "- produce the histogram and rank plots.\n",
    "\n",
    "Their purpose is to let you focus on **interpretation**, not bookkeeping.\n",
    "\n",
    "You will then:\n",
    "1. Paste the paths to your **analog** and **VR** `eventQ_t0.tsv` files.\n",
    "2. Run the diagnostics for both cases.\n",
    "3. Decide whether VR improves stability **without introducing weight pathologies**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cb621-c22f-4c7b-a686-4bd91b6b0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def load_eventQ(eventQ_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a single eventQ TSV produced by the RunAction.\n",
    "    Expected format: 2 columns -> eventID, eventQ (tab-separated).\n",
    "    Lines starting with '#' are ignored.\n",
    "    \"\"\"\n",
    "    p = Path(eventQ_path).expanduser()\n",
    "    if not p.is_file():\n",
    "        raise FileNotFoundError(f\"TSV not found: {p}\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        p,\n",
    "        sep=\"\\t\",\n",
    "        comment=\"#\",\n",
    "        header=None,\n",
    "        names=[\"eventID\", \"eventQ\"],\n",
    "    )\n",
    "    df[\"eventQ\"] = pd.to_numeric(df[\"eventQ\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"eventQ\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def stability_diagnostics(df: pd.DataFrame, label: str = \"run\") -> dict:\n",
    "    q = df[\"eventQ\"].to_numpy(dtype=float)\n",
    "    n = q.size\n",
    "    total = float(q.sum())\n",
    "\n",
    "    q_sorted = np.sort(q)\n",
    "    median = float(np.median(q_sorted)) if n > 0 else np.nan\n",
    "    qmax = float(q_sorted[-1]) if n > 0 else np.nan\n",
    "\n",
    "    # Descending for top-k\n",
    "    q_desc = q_sorted[::-1]\n",
    "    top1 = float(q_desc[0]) if n > 0 else 0.0\n",
    "    top10 = float(q_desc[:10].sum()) if n >= 10 else float(q_desc.sum())\n",
    "\n",
    "    frac_zero = float((q == 0.0).mean()) if n > 0 else np.nan\n",
    "    frac_pos  = float((q > 0.0).mean()) if n > 0 else np.nan\n",
    "\n",
    "    top1_frac  = float(top1 / total) if total > 0 else np.nan\n",
    "    top10_frac = float(top10 / total) if total > 0 else np.nan\n",
    "\n",
    "    # Spike indicator (guard median=0)\n",
    "    spike = np.inf\n",
    "    if np.isfinite(median) and median != 0.0:\n",
    "        spike = float(qmax / median)\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"N_events\": int(n),\n",
    "        \"sum_Q\": total,\n",
    "        \"mean_Q\": float(q.mean()) if n > 0 else np.nan,\n",
    "        \"median_Q\": median,\n",
    "        \"max_Q\": qmax,\n",
    "        \"frac_Q_eq_0\": frac_zero,\n",
    "        \"frac_Q_gt_0\": frac_pos,\n",
    "        \"top1_frac_of_sum\": top1_frac,\n",
    "        \"top10_frac_of_sum\": top10_frac,\n",
    "        \"max_over_median\": spike,\n",
    "    }\n",
    "\n",
    "def print_stability_report(stats: dict) -> None:\n",
    "    print(f\"--- Stability report: {stats['label']} ---\")\n",
    "    print(f\"N events          : {stats['N_events']}\")\n",
    "    print(f\"Mean(Q_event)     : {stats['mean_Q']:.6e}\")\n",
    "    print(f\"Median(Q_event)   : {stats['median_Q']:.6e}\")\n",
    "    print(f\"Max(Q_event)      : {stats['max_Q']:.6e}\")\n",
    "    print(f\"Frac(Q=0)         : {100*stats['frac_Q_eq_0']:.2f}%\")\n",
    "    print(f\"Frac(Q>0)         : {100*stats['frac_Q_gt_0']:.2f}%\")\n",
    "    print(f\"Top-1 frac (sum)  : {100*stats['top1_frac_of_sum']:.2f}%\")\n",
    "    print(f\"Top-10 frac (sum) : {100*stats['top10_frac_of_sum']:.2f}%\")\n",
    "    print(f\"Max/Median        : {stats['max_over_median']:.2e}\")\n",
    "\n",
    "def plot_eventQ_hist(df: pd.DataFrame, title: str) -> None:\n",
    "    q = df[\"eventQ\"].to_numpy(dtype=float)\n",
    "    plt.figure()\n",
    "    plt.hist(q, bins=80)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Q_event\")\n",
    "    plt.ylabel(\"Counts (log scale)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90eceeb-a320-405f-aead-e7754b3d423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the TWO eventQ paths you recorded earlier:\n",
    "#eventQ_vr_path = \"PASTE_HERE/VR_run/eventQ_t0.tsv\"\n",
    "#eventQ_an_path = \"PASTE_HERE/analog_run/eventQ_t0.tsv\"\n",
    "eventQ_vr_path = \"out/1768483526750743_pid7580_0/eventQ_t0.tsv\"\n",
    "eventQ_an_path = \"out/1768483482043996_pid7567_0/eventQ_t0.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0477f8-cbb8-4d1d-910e-3b0d8098e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr = load_eventQ(eventQ_vr_path)\n",
    "df_an = load_eventQ(eventQ_an_path)\n",
    "\n",
    "stats_vr = stability_diagnostics(df_vr, label=\"VR (10k)\")\n",
    "stats_an = stability_diagnostics(df_an, label=\"Analog (100k)\")\n",
    "\n",
    "print_stability_report(stats_vr)\n",
    "plot_eventQ_hist(df_vr, title=\"VR (10k): Q_event histogram\")\n",
    "\n",
    "print_stability_report(stats_an)\n",
    "plot_eventQ_hist(df_an, title=\"Analog (100k): Q_event histogram\")\n",
    "\n",
    "# Compact side-by-side summary table\n",
    "summary = pd.DataFrame([stats_an, stats_vr])[[\n",
    "    \"label\",\"N_events\",\"frac_Q_eq_0\",\"top1_frac_of_sum\",\"top10_frac_of_sum\",\"max_over_median\"\n",
    "]]\n",
    "summary[\"frac_Q_eq_0_%\"] = 100*summary[\"frac_Q_eq_0\"]\n",
    "summary[\"top1_%\"] = 100*summary[\"top1_frac_of_sum\"]\n",
    "summary[\"top10_%\"] = 100*summary[\"top10_frac_of_sum\"]\n",
    "summary = summary.drop(columns=[\"frac_Q_eq_0\",\"top1_frac_of_sum\",\"top10_frac_of_sum\"])\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2bd94-3de2-4d20-a55d-3651f0d01940",
   "metadata": {},
   "source": [
    "## Check 3 ‚Äî Stability: interpret the event-level diagnostics (analog vs VR)\n",
    "\n",
    "You have produced, for **Analog (100k)** and **VR (10k)**:\n",
    "\n",
    "- a histogram of `Q_event`,\n",
    "- a stability report with summary diagnostics.\n",
    "\n",
    "Use **both the histogram and the numbers** below to answer.\n",
    "\n",
    "---\n",
    "\n",
    "### A) What does the distribution look like?\n",
    "\n",
    "1) **Zeros vs non-zeros**\n",
    "- Compare `Frac(Q=0)` in analog and VR.\n",
    "- What does this immediately tell you about *how* the total score is built in each case?\n",
    "\n",
    "2) **Typical event contribution (VR)**\n",
    "- Compare **median** and **mean** for VR.\n",
    "- Are they close? What does that imply about event-to-event variability?\n",
    "\n",
    "3) **Rare-event pattern (analog)**\n",
    "- In the analog run, the median is 0 but the mean is non-zero.\n",
    "- Explain in one sentence what this implies about the distribution of event contributions.\n",
    "\n",
    "---\n",
    "\n",
    "### B) Who carries the total score?\n",
    "\n",
    "4) **Dominance test (top-1 / top-10)**\n",
    "- Use `Top-1 frac (sum)` and `Top-10 frac (sum)`:\n",
    "  - Which run is dominated by a handful of events?\n",
    "  - Which run distributes the total sum across many events?\n",
    "\n",
    "5) **Back-of-the-envelope: how many contributing events in analog?**\n",
    "- Use: total sum $\\approx \\mathrm{Mean}(Q_{\\mathrm{event}})\\times N_{\\mathrm{events}}$.\n",
    "- If analog contributions are mostly 0 or 1, estimate how many events had $Q_{\\mathrm{event}}=1$.\n",
    "- Does that agree with the reported `Frac(Q>0)`?\n",
    "\n",
    "---\n",
    "\n",
    "### C) Stability verdict + red flags\n",
    "\n",
    "6) **Stability verdict**\n",
    "Using `max/median`, the top-1/top-10 fractions, and the histogram shape:\n",
    "\n",
    "- Does the VR run show any sign of pathological spikes or heavy tails?\n",
    "- Does the analog run show event-level instability (domination by rare events)?\n",
    "\n",
    "7) **What would a *bad* VR setup look like in these diagnostics? (give two signatures)**  \n",
    "Examples:\n",
    "- extremely large `max/median`,\n",
    "- top-1 or top-10 carrying a large fraction of the total sum,\n",
    "- a histogram with a visible ‚Äúspike far to the right‚Äù (rare extreme contributions).\n",
    "\n",
    "---\n",
    "\n",
    "### One-sentence takeaway (must cite at least two diagnostics)\n",
    "\n",
    "Write one sentence comparing analog vs VR stability, explicitly citing:\n",
    "- one histogram feature, and\n",
    "- one numeric diagnostic (e.g. `Frac(Q=0)`, `Top-10 frac`, or `max/median`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d4dd8-c2a4-4fdc-8884-78f136f19fe6",
   "metadata": {},
   "source": [
    "## Final conclusion ‚Äî evaluating a rare-event Monte Carlo strategy\n",
    "\n",
    "This hands-on was not about producing a single number.\n",
    "It was about learning **how to evaluate a Monte Carlo strategy for a rare-event observable**.\n",
    "\n",
    "You studied the *same physical problem* using two approaches:\n",
    "\n",
    "- **Analog sampling**\n",
    "- **Variance reduction (forced interactions with weights)**\n",
    "\n",
    "and evaluated them using **three essential checks**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Accuracy ‚Äî correctness comes first\n",
    "\n",
    "Use:\n",
    "- Analog reference: **(100M)**  ‚Üí $\\mu_a$, $\\sigma_a$\n",
    "- VR run: **(10k)**            ‚Üí $\\mu_{vr}$, $\\sigma_{vr}$\n",
    "\n",
    "Compute:\n",
    "$$\n",
    "z=\\frac{\\mu_{vr}-\\mu_a}{\\sqrt{\\sigma_{vr}^2+\\sigma_a^2}}\n",
    "$$\n",
    "\n",
    "**Report:**\n",
    "- $\\mu_a =$ ________ , $\\sigma_a =$ ________\n",
    "- $\\mu_{vr} =$ ________ , $\\sigma_{vr} =$ ________\n",
    "- $z =$ ________\n",
    "\n",
    "**Accuracy conclusion (1 line):**  \n",
    "Is $|z|\\lesssim 2$? What does that imply about bias?  \n",
    "_____________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Stability ‚Äî event-level behaviour matters\n",
    "\n",
    "Use the `eventQ_t0.tsv` diagnostics for:\n",
    "- Analog baseline: **(100k)**\n",
    "- VR run: **(10k)**\n",
    "\n",
    "Write down at least **two** of the following for *each* run:\n",
    "- `Frac(Q=0)` = ________ (analog) vs ________ (VR)\n",
    "- `Top-10 frac (sum)` = ________ (analog) vs ________ (VR)\n",
    "- `max/median` = ________ (analog) vs ________ (VR)\n",
    "\n",
    "**Stability conclusion (1‚Äì2 lines):**  \n",
    "Is the estimator dominated by a handful of events in either case?  \n",
    "_____________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Efficiency ‚Äî precision per unit time\n",
    "\n",
    "Use the summaries from:\n",
    "- Your best analog run (e.g. **100k**) ‚Üí $R_a$, $T_a$, $\\mathrm{FOM}_a$\n",
    "- VR run (**10k**)                     ‚Üí $R_{vr}$, $T_{vr}$, $\\mathrm{FOM}_{vr}$\n",
    "\n",
    "Compute and report:\n",
    "- $R_a/R_{vr} =$ ________\n",
    "- $T_{vr}/T_a =$ ________\n",
    "- $\\mathrm{FOM}_{vr}/\\mathrm{FOM}_a =$ ________\n",
    "\n",
    "**Efficiency conclusion (1‚Äì2 lines):**  \n",
    "Is the improvement incremental, or orders of magnitude?  \n",
    "_____________________________________________________________\n",
    "\n",
    "---\n",
    "\n",
    "## Final takeaway (mandatory synthesis)\n",
    "\n",
    "Write **one short paragraph (3‚Äì4 lines)** answering:\n",
    "\n",
    "> *For this observable, is variance reduction optional or essential?  \n",
    "> Justify using **accuracy**, **stability**, and **efficiency** with at least one number in each.*\n",
    "\n",
    "Avoid generic statements. Refer explicitly to what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a2ce2-efb6-4a4e-a915-3a448d24e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
